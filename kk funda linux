HISTORY

history         # Display all history
history -c      # Clear entire command history
history N       # Show last N commands
history | grep <command>  # Search history for a specific command
!!              # Re-run the last executed command
!<line_number>  # Run a specific command from history by line number
!<string>       # Run the most recent command that starts with <string>
history -d 500  # Delete the command at history line number 500
--------------------------------------------------------------------------------
mkdir -m 755 public     # Create 'public' with specific permissions
-------------------------------------------------------------------------------
cd ../..            # Move two levels up
cd or cd ~          # Move to the home directory
cd -                # Switch between current and previous directories
-------------------------------------------------------------------------------
cp devops.txt DevOps/  # Copy file to a directory
cp -R Python DevOps/  # Copy an entire directory recursively
------------------------------------------------------------------------------
grep "UNIX" abc.txt  # Case-sensitive search
grep -i "UNIX" abc.txt  # Case-insensitive search
grep -c "UNIX" abc.txt  # Count occurrences
grep -l "UNIX" *  # Show files containing 'UNIX'
grep -w "UNIX" abc.txt  # Match whole words only
grep -o "UNIX" abc.txt  # Show only matching content
grep -n "UNIX" abc.txt  # Show line numbers
grep -v "UNIX" abc.txt  # Show lines that do NOT match
grep -B5 "error" demo.txt  # Show 5 lines *before* match
grep -A5 "error" demo.txt  # Show 5 lines *after* match
grep -C5 "error" demo.txt  # Show 5 lines *before & after*
--------------------------------------------------------------------------------
chmod -v 644 file.txt --> what changes done it will show.
------------------------------------------------------------------------------
VI EDITOR

:se nu        # Show line numbers
:se nonu      # Hide line numbers
:90           # Go to line 90
/data         # Search for 'data'
dd            # Delete a line
u             # Undo
--------------------------------------------------------------------------------
FIND

find . -type f -empty                 # Find empty files in current directory
find ~ -type f -empty                # Find empty files in home directory
find /tmp -type f -empty            # Find empty files in /tmp
find . -type d -name <dirName>      # Search directory by name

find . -name deployment.yaml         # Case-sensitive search
find . -i name deployment.yaml        # Case-insensitive search
find . -type f -perm 0777            # Files with 777 permissions

find . -mtime 1                      # Modified exactly 1 day ago
find . -mtime -1                     # Modified less than 1 day ago
find . -mtime +1                     # Modified more than 1 day ago

find ./ -type f -name "*.txt"        # Find all .txt files
--------------------------------------------------------------------------------
sed Command (Stream Editor)

sed 's/unix/linux/' abc.txt          # Replace first occurrence
sed 's/unix/linux/2' abc.txt         # Replace 2nd occurrence
sed 's/unix/linux/g' abc.txt         # Replace all occurrences

sed '3 s/unix/linux/' abc.txt        # Replace on line 3
sed '3 s/am/was/p' sed.txt           # Duplicate replaced line
sed -n 's/am/was/p' sed.txt          # Print only replaced lines

sed '1,3 s/unix/linux/' abc.txt      # Replace in line range
sed '5d' filename.txt                # Delete line 5
sed '3,6d' filename.txt              # Delete lines 3 to 6
sed -n '60,80p' filename             # To display lines 60 to 80 of a file using sed
-------------------------------------------------------------------------------------
whereis mkdir -- Find binary, source, and manual files for a command.(Use case: Useful when troubleshooting or understanding where commands are stored.)
-------------------------------------------------------------------------------------
systemctl and service

# List all services
systemctl list-unit-files   # Press 'q' to quit

# Service status
systemctl status sshd

# Start/Stop/Restart
service sshd start
service sshd stop
-------------------------------------------------------------------------------------
last

last
last -R ec2-user    # Show for specific user
last -F             # Show login/logout times
-------------------------------------------------------------------------------------
sudo usermod -aG devops kkfunda -- Add a User to a Group with usermod
sudo lid -g devops -- Verify Group Members:
id kkfunda          # Shows UID, GID, and group membership
groups kkfunda      # Lists all groups the user belongs to
------------------------------------------------------------------------------------
lscpu                 # Display CPU architecture info
lshw                  # Show detailed hardware info (needs root)
-----------------------------------------------------------------------------------
sudo shutdown now     # Shutdown system immediately
watch -d free -h      # Monitor memory usage live with highlight
------------------------------------------------------------------------------------
free
=====

The free command in Linux is used to display information about the system's memory usage. It provides details about total memory, used memory, free memory, and memory used by buffers/cache, which can help you monitor how your system's RAM is being utilized.

Useful options for the free command:

free -h: Displays the memory in a human-readable format (e.g., GB, MB).
free -m: Shows the memory in megabytes.
free -g: Shows the memory in gigabytes.
free -s <seconds>: Repeats the output every <seconds>.
free -t: Shows the total memory (including swap).

AWK command
============
 
-> awk '{print}' table.txt  —-> display the complete data. 
-> awk '/manager/ {print}' table.txt  —> manger matches.
-> awk '{print $0}' table.txt  → Display the complete data.
→  awk '{print $1,$4}' table.txt

→ awk '{print NR,$1,$4}' table.txt   --> NR means row number

→ awk '{print NR,$1,$NF}' table.txt  → NF means last field 
—> awk 'NR==3, NR==6 {print NR,$0}' table.txt   --> row 3 to 6
→ awk '{print $1,"----->",$4}' table.txt

-> awk '$3 > 50 {print $1, $2}' table.txt

-> awk 'NR >= 10 && NR <= 20' file.txt --> This will print lines 10 to 20 from file.txt

-> awk '{print $1, $2 * $3}' file.txt


awk command use cases
======================

1. Log File Analysis
--------------------
system administrators often use awk to analyze log files (e.g., Apache logs, system logs) for errors or performance metrics.

Example: Find the number of error entries in an Apache log:


awk '$9 >= 400 {print $0}' access.log

This command looks for HTTP status codes greater than or equal to 400 (indicating errors like 404 or 500) and prints the log entries with errors.

2. User Data Extraction
-----------------------

who -u | awk '{print $1, $3, $4}'

This extracts the username, login date, and login time for users currently logged in.


3. Server Log Parsing (Parsing and Filtering Logs)
--------------------------------------------------

awk '$1 == "192.168.1.100" {print $0}' access.log

ex:
192.168.1.1 - - [01/Feb/2025:12:34:56 +0000] "GET /index.html HTTP/1.1" 200 2345 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36"
192.168.1.1 - - [01/Feb/2025:12:34:56 +0000] "GET /index.html HTTP/1.1" 200 2345 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36"

192.168.1.100 - - [01/Feb/2025:12:34:56 +0000] "GET /index.html HTTP/1.1" 200 2345 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36"

192.168.1.1 - - [01/Feb/2025:12:34:56 +0000] "GET /index.html HTTP/1.1" 200 2345 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36"

192.168.1.1 - - [01/Feb/2025:12:34:56 +0000] "GET /index.html HTTP/1.1" 200 2345 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36"



This filters log entries for requests coming from IP address 192.168.1.100.


4. Monitoring Disk Usage
------------------------

df -h | awk '{gsub("%", "", $5); if ($5+0 > 18) print $1, $5 "%"}'

This prints all filesystems that are over 90% full, which is useful for system monitoring and alerting.

wget
====

The wget command in Linux is a widely used tool for downloading files from the web. It supports downloading via HTTP, HTTPS, and FTP protocols, and it can handle things like resuming interrupted downloads or downloading multiple files at once.


Ex: wget https://dlcdn.apache.org/maven/maven-3/3.9.9/binaries/apache-maven-3.9.9-bin.tar.gz

cron tab: scheduling tasks
===========================


syntax:
-------

* * * * * /path/to/command
- - - - -
| | | | |  
| | | | +---- Day of the week (0 - 6) (Sunday = 0)
| | | +------ Month (1 - 12)
| | +-------- Day of the month (1 - 31)
| +---------- Hour (0 - 23)
+------------ Minute (0 - 59)



→ Crontab is available for all the users.
crontab -l  : How many jobs are currently configure.
crontab -e  —>edit the crontab
crontab -r  —> remove the crontab
#crontab -l -u kkfunda  → to see other users crontab, only root user can run this.

$sudo touch /etc/cron.allow  —> remove cron access to normal user.
#sudo vi /etc/cron.allow  —> add user here.

vi hello.sh

echo “welcome to KK FUNDA”
echo “today date is:”
date
uptime

How to run the shell script?

sh hello.sh  —-> It will run
./hello.sh    —--> don't have exec permissions → chmod u+x hello.sh

*/1 * * * * /home/ec2-user/hello.sh  >> /home/ec2-user/hello.log



crontab -e —-> paste that command
crontab -l
NOTE: we dont want to loose the previous o/p[ >> ]  → append the standard o/p.

------------------------------------------------------------------------------------------------------------------------------
op 20 Docker Scenario-Based Interview Questions (Enhanced for 4+ Years Experience)
1. Container keeps restarting – how do you fix it?
In one of our dev environments, a Node.js container was stuck in a crash loop. Using docker ps -a, I found the container kept exiting with code 1. I ran docker logs <container_id> and identified the error — it was due to a missing environment variable. I fixed the variable in the Docker Compose file, restarted the service, and the container stabilized. This type of issue is common when configuration isn't validated before deployment. We later added a pre-deployment config check script to catch such issues earlier.

Docker Architecture

2. Docker container not able to access the internet – what will you check?
We faced this in staging where a container couldn’t reach external APIs. I entered the container using docker exec and tried ping 8.8.8.8 and curl google.com. It failed, confirming DNS issues. The container was on the default bridge network. I fixed it by adding a custom bridge network and configured Docker daemon to use Google's DNS via /etc/docker/daemon.json. Restarted the Docker service, and everything worked fine. Later, we used network_mode: host in critical network-bound services to avoid isolation.

3. Docker image too large – how will you optimize?
Our Spring Boot image was 1.2GB. This was slowing builds and pushing large layers to the registry. I rewrote the Dockerfile using a multi-stage build. The first stage compiled the JAR, and the second used a minimal openjdk-alpine image. We also removed build tools and cleaned up cache files. This reduced our image size to 250MB. The deployment time reduced significantly, and ECR storage bills went down too.

4. Code updated, but container still runs old code – why?
A Python app container was serving stale code. I realized Docker was caching previous layers. I used --no-cache during build and moved the COPY instruction below the RUN pip install step. This ensured dependencies were cached but new source code was always copied fresh. Post this fix, our CI pipeline was updated to force clean builds during major releases.

5. Two containers can’t talk – how do you fix it?
In a Docker Compose setup, the app couldn’t reach MySQL. I checked that both containers were in the same Docker-defined network. The app was trying to connect using localhost. I updated the DB host to the service name (db) and restarted the stack. Docker's internal DNS resolved the name. We later introduced a shared overlay network in Swarm for multi-host communication.

6. Data gets lost after container restart – what to do?
A MySQL container would lose all data when restarted. I realized the data directory wasn’t persisted. I added a named volume like mysql_data:/var/lib/mysql in Docker Compose. After that, even after recreating the container, the data remained intact. We also scheduled weekly volume backups to S3 for disaster recovery.

7. Dockerfile changes not reflecting – what's the fix?
We updated package.json, but npm install wasn't picking new packages. Docker reused the cached layer. I changed the order in the Dockerfile to COPY package.json → RUN npm install → COPY . .. This leveraged caching for dependencies and rebuilt app code properly. We also enabled --no-cache in nightly builds to avoid stale layers.

8. App is running but not accessible via browser – what’s the issue?
The app inside the container was listening on localhost, which doesn’t expose to host machine. I updated it to bind 0.0.0.0, and ran the container with -p 8080:8080. Also verified host firewall rules. After that, the app was accessible externally. We documented this as a checklist item for all new Dockerized apps.

9. Docker Compose service failing to start – how did you fix it?
The app container failed to connect to DB with 'connection refused'. Logs showed it tried connecting before DB was ready. I added depends_on and a wait-for-it.sh script to delay the app startup until the DB port was open. This stabilized the startup sequence. We also added health checks for DB to make it more robust.

10. Builds are slow due to Docker caching – how did you improve?
Each build was reinstalling dependencies, wasting time. I restructured the Dockerfile: first copied package.json, then ran npm install, then copied source code. As dependencies changed less frequently, Docker reused that layer. This reduced our build time from 4 mins to 1.5 mins in CI/CD.

11. How do you update a container in production without downtime?
We used a rolling deployment strategy. Behind a load balancer, I deployed a new container, verified health checks, and only then removed the old version. No downtime was observed. In Kubernetes, this was handled using RollingUpdate strategy in Deployment YAML.

12. Container exits immediately – what steps do you take?
One backend container kept exiting. I used docker logs and found a missing config.json. The volume was incorrectly mounted. Fixed the path in Compose file, rebuilt the container, and confirmed the issue was resolved. To prevent recurrence, we added a pre-run validation step to check mounted file presence.

13. How do you troubleshoot inside a running container?
I used docker exec -it <container> /bin/sh to explore the container. Used ls, cat, ps, top to check logs, running processes, and file contents. For Python apps, I checked gunicorn logs and confirmed dependencies using pip list inside the container.

14. No logs showing for a running container – what could be wrong?
The app was configured to write logs to a file instead of STDOUT. I updated the logging config to write to stdout so Docker could capture it. This enabled docker logs and integrated well with centralized logging using ELK.

15. How do you share data between two containers?
We needed our app to write logs and a separate container to parse them. I created a named volume and mounted it to both containers. This allowed real-time access to logs. This method was later used for audit logs and file processing as well.

16. How do you manage secrets in Docker?
In dev, we used .env files. But in production, we used Docker Swarm secrets, which mounted sensitive values as in-memory files with strict permissions. It reduced the risk of leaking credentials inside image layers or logs.

17. How do you clean unused Docker images, volumes, and containers?
On our GitLab runners, disk usage was high due to old layers. I scheduled docker system prune -f, docker volume prune -f, and docker image prune -a -f. Also added registry cleanup rules to remove images older than 15 days. Alerts were integrated for disk usage using Prometheus + Alertmanager.

18. How do you identify which image or layer is consuming most space?
I used docker image ls, docker image inspect, and docker history. This showed which layers were largest — usually caused by large packages or COPY . including unnecessary files. We then optimized by creating .dockerignore and using minimal base images.

19. How do you test Docker images before pushing to production?
I tagged the image locally as myapp:dev, ran it using -p to test endpoints with Postman. Also checked logs, volume mounts, and env vars. After testing, I tagged it as latest and pushed it to the container registry.

20. Difference between build-time and run-time variables – how do you handle them?
Build-time variables are passed using --build-arg and are only used during image creation. Runtime variables are passed via -e or Compose files, used during container execution. We clearly separated them in Dockerfile using ARG and ENV.